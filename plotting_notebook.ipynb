{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2506c82e",
   "metadata": {},
   "source": [
    "----\n",
    "Overview of notebook:\n",
    "----\n",
    "Set up plotting variables\n",
    "\n",
    "Section 1: \n",
    "    * Beh Plots\n",
    "\n",
    "Section 2: \n",
    "    * Plots for Parametric Modulation analyses\n",
    "\n",
    "Section 3:\n",
    "    * Plots for Decoding analyses\n",
    "\n",
    "Section 4:\n",
    "    * Plots for Network Hubs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80edadb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import packages we will need\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import numpy.matlib as mb\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.colors as mcolors\n",
    "import seaborn as sns\n",
    "import pickle\n",
    "import os\n",
    "import sys\n",
    "import re\n",
    "import glob as glob\n",
    "import argparse\n",
    "import nilearn\n",
    "from nilearn import datasets, plotting, surface\n",
    "from nilearn.image import resample_img\n",
    "from nilearn import masking\n",
    "from nilearn import image\n",
    "from nilearn.input_data import NiftiMasker\n",
    "from nilearn.input_data import NiftiLabelsMasker\n",
    "from nilearn.glm import threshold_stats_img\n",
    "from nilearn.datasets import load_fsaverage_data\n",
    "from nilearn.plotting import plot_img_on_surf\n",
    "from nilearn.plotting import plot_surf_contours\n",
    "import nibabel as nib\n",
    "\n",
    "def create_nii(stats_mat, cortical_mask):\n",
    "    cortical_masker = NiftiMasker(cortical_mask)\n",
    "    cortical_masker.fit()\n",
    "    stat_nii = cortical_masker.inverse_transform(stats_mat)\n",
    "    return stat_nii\n",
    "\n",
    "# define function to save out plots of model outputs\n",
    "def gen_model_plots(c_tState, c_tTask, c_tProp, c_state, c_task, c_color, plot_filename, tResp, t_belief_alpha, c_belief_alpha):\n",
    "    err_colors = ['grey','orange','red','white']\n",
    "    err_ys = [-0.1, -0.125, -0.15, -.2]\n",
    "    # make MODEL ESTIMATE plots\n",
    "    plt.rcParams[\"figure.figsize\"] = (50,20)\n",
    "    fig, axs = plt.subplots(3,1) # rows, columns\n",
    "    \n",
    "    axs[0].plot(c_tState, 'black', alpha=t_belief_alpha)\n",
    "    axs[0].plot(c_state, 'blue', alpha=c_belief_alpha)\n",
    "    for x_coord in range(len(c_tState)):\n",
    "        axs[0].plot(x_coord, err_ys[tResp[x_coord]], color=err_colors[tResp[x_coord]], marker='o', alpha=0.25)\n",
    "    axs[0].set_ylabel(\"STATE\", rotation=0, fontsize=25, labelpad=20)\n",
    "    \n",
    "    axs[1].plot(c_tTask, 'black', alpha=t_belief_alpha)\n",
    "    axs[1].plot(c_task, 'green', alpha=c_belief_alpha)\n",
    "    for x_coord in range(len(c_tTask)):\n",
    "        axs[1].plot(x_coord, err_ys[tResp[x_coord]], color=err_colors[tResp[x_coord]], marker='o', alpha=0.25)\n",
    "    axs[1].set_ylabel(\"TASK\", rotation=0, fontsize=25, labelpad=20)\n",
    "    \n",
    "    axs[2].plot(c_tProp, 'black', alpha=t_belief_alpha)\n",
    "    axs[2].plot(c_color, 'gold', alpha=c_belief_alpha)\n",
    "    for x_coord in range(len(c_tProp)):\n",
    "        axs[2].plot(x_coord, err_ys[tResp[x_coord]], color=err_colors[tResp[x_coord]], marker='o', alpha=0.25)\n",
    "    axs[2].set_ylabel(\"COLOR\", rotation=0, fontsize=25, labelpad=20)\n",
    "    \n",
    "    plt.show()\n",
    "    plt.savefig(plot_filename)\n",
    "    plt.close()\n",
    "\n",
    "# -------------------------------------------------\n",
    "# -- project folder directory\n",
    "dataset_dir = \"/mnt/nfs/lss/lss_kahwang_hpc/data/FPNHIU/\"\n",
    "\n",
    "# -- roi mask directory\n",
    "mask_dir = \"/mnt/nfs/lss/lss_kahwang_hpc/ROIs/\"\n",
    "cortical_mask = nib.load(mask_dir + \"CorticalMask_RSA_task-Quantum.nii.gz\")\n",
    "cortical_mask_data = cortical_mask.get_fdata()\n",
    "\n",
    "# -- csv directory\n",
    "data_dir = \"/mnt/nfs/lss/lss_kahwang_hpc/data/FPNHIU/CSVs/\"\n",
    "\n",
    "# -- model data directory\n",
    "model_data_output = \"/mnt/nfs/lss/lss_kahwang_hpc/data/FPNHIU/model_data/\"\n",
    "\n",
    "# -- set sns theme\n",
    "sns.set_theme(context='poster', style='whitegrid', )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a767a975",
   "metadata": {},
   "source": [
    "Section 1\n",
    "\n",
    "# ------------------------------------------------------------------------------------------\n",
    "# - - - - - - - - - - - - - - - - -\n",
    "# - -   Behavioral Plots   - -\n",
    "# - - - - - - - - - - - - - - - - -"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06e43541",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" Load CSV files and create a master file with all subjects \"\"\"\n",
    "# Load ouptut csv files for the two tasks and put each in their own respective master files (all subjects in long format)\n",
    "# - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - -\n",
    "# get list of files for each task\n",
    "pilots_to_exclude=[\"10190\",\"10162\",\"10260\",\"10261\",\"10245\"]\n",
    "subjs_to_exclude = [\"10296\", \"10319\", \"10275\", \"10321\", \"10218\", \"10318\", \"10322\", \"10118\", \"10282\", \"10351\", \"10393\", \"10358\"]\n",
    "DM_list = glob.glob(os.path.join(model_data_output,(\"*_dataframe_3dDeconvolve_pSpP.csv\"))) #withModelEstimates.csv\")))  dataframe_model-pSpP\n",
    "print(DM_list)\n",
    "DM_df_list = []\n",
    "DM_usable_list = []\n",
    "for cur_DM in sorted(DM_list):\n",
    "    # load pSpP file\n",
    "    temp_df = pd.read_csv(cur_DM)\n",
    "    temp_df[\"block\"]=temp_df[\"block\"]+1 #fix python index\n",
    "    temp_df = temp_df[temp_df['block']<6]\n",
    "    #print(len(temp_df))\n",
    "    \n",
    "    # add subject information\n",
    "    sid=re.search(\"[0-9]{5}\", cur_DM)\n",
    "    if sid:\n",
    "        temp_df[\"Participant_ID\"] = sid.group(0)\n",
    "    \n",
    "    # -- load control model 1\n",
    "    with open(os.path.join(model_data_output,(\"sub-\"+sid.group(0)+\"_pSdP_belief-state.p\")), 'rb') as handle:\n",
    "        pSdP_sE_belief = pickle.load(handle)\n",
    "    with open(os.path.join(model_data_output,(\"sub-\"+sid.group(0)+\"_pSdP_belief-color.p\")), 'rb') as handle:\n",
    "        pSdP_cE_belief = pickle.load(handle)\n",
    "    with open(os.path.join(model_data_output,(\"sub-\"+sid.group(0)+\"_pSdP_belief-task.p\")), 'rb') as handle:\n",
    "        pSdP_tE_belief = pickle.load(handle)\n",
    "    with open(os.path.join(model_data_output,(\"sub-\"+sid.group(0)+\"_pSdP_belief-task.p\")), 'rb') as handle:\n",
    "        pSdP_entropy = pickle.load(handle)\n",
    "    temp_df[\"pSdP_sE\"] = pSdP_sE_belief[:200,0]\n",
    "    temp_df[\"pSdP_tE\"] = pSdP_tE_belief[:200]\n",
    "    temp_df[\"pSdP_cE\"] = pSdP_cE_belief[:200]\n",
    "    temp_df[\"pSdP_entropy\"] = pSdP_entropy[:200]\n",
    "    \n",
    "    # -- load control model 2\n",
    "    with open(os.path.join(model_data_output,(\"sub-\"+sid.group(0)+\"_dSpP_belief-state.p\")), 'rb') as handle:\n",
    "        dSpP_sE_belief = pickle.load(handle)\n",
    "    with open(os.path.join(model_data_output,(\"sub-\"+sid.group(0)+\"_dSpP_belief-color.p\")), 'rb') as handle:\n",
    "        dSpP_cE_belief = pickle.load(handle)\n",
    "    with open(os.path.join(model_data_output,(\"sub-\"+sid.group(0)+\"_dSpP_belief-task.p\")), 'rb') as handle:\n",
    "        dSpP_tE_belief = pickle.load(handle)\n",
    "    with open(os.path.join(model_data_output,(\"sub-\"+sid.group(0)+\"_dSpP_belief-task.p\")), 'rb') as handle:\n",
    "        dSpP_entropy = pickle.load(handle)\n",
    "    temp_df[\"dSpP_sE\"] = dSpP_sE_belief[:200,0]\n",
    "    temp_df[\"dSpP_tE\"] = dSpP_tE_belief[:200]\n",
    "    temp_df[\"dSpP_cE\"] = dSpP_cE_belief[:200]\n",
    "    temp_df[\"dSpP_entropy\"] = dSpP_entropy[:200]\n",
    "    \n",
    "    # -- load control model 3\n",
    "    with open(os.path.join(model_data_output,(\"sub-\"+sid.group(0)+\"_dSdP_belief-state.p\")), 'rb') as handle:\n",
    "        dSdP_sE_belief = pickle.load(handle)\n",
    "    with open(os.path.join(model_data_output,(\"sub-\"+sid.group(0)+\"_dSdP_belief-color.p\")), 'rb') as handle:\n",
    "        dSdP_cE_belief = pickle.load(handle)\n",
    "    with open(os.path.join(model_data_output,(\"sub-\"+sid.group(0)+\"_dSdP_belief-task.p\")), 'rb') as handle:\n",
    "        dSdP_tE_belief = pickle.load(handle)\n",
    "    with open(os.path.join(model_data_output,(\"sub-\"+sid.group(0)+\"_dSdP_belief-task.p\")), 'rb') as handle:\n",
    "        dSdP_entropy = pickle.load(handle)\n",
    "    temp_df[\"dSdP_sE\"] = dSdP_sE_belief[:200,1]\n",
    "    temp_df[\"dSdP_tE\"] = dSdP_tE_belief[:200]\n",
    "    temp_df[\"dSdP_cE\"] = dSdP_cE_belief[:200]\n",
    "    temp_df[\"dSdP_entropy\"] = dSdP_entropy[:200]\n",
    "    \n",
    "    # -- load control model 4\n",
    "    with open(os.path.join(model_data_output,(\"sub-\"+sid.group(0)+\"_pSjP_belief-state.p\")), 'rb') as handle:\n",
    "        pSjP_sE_belief = pickle.load(handle)\n",
    "    with open(os.path.join(model_data_output,(\"sub-\"+sid.group(0)+\"_pSjP_belief-color.p\")), 'rb') as handle:\n",
    "        pSjP_cE_belief = pickle.load(handle)\n",
    "    with open(os.path.join(model_data_output,(\"sub-\"+sid.group(0)+\"_pSjP_belief-task.p\")), 'rb') as handle:\n",
    "        pSjP_tE_belief = pickle.load(handle)\n",
    "    with open(os.path.join(model_data_output,(\"sub-\"+sid.group(0)+\"_pSjP_belief-task.p\")), 'rb') as handle:\n",
    "        pSjP_entropy = pickle.load(handle)\n",
    "    temp_df[\"pSjP_sE\"] = pSjP_sE_belief[:200,0] # temp_df5[\"pSjP_sE\"]\n",
    "    temp_df[\"pSjP_tE\"] = pSjP_tE_belief[:200] # temp_df5[\"pSjP_tE\"]\n",
    "    temp_df[\"pSjP_cE\"] = pSjP_cE_belief[:200] # temp_df5[\"pSjP_cE\"]\n",
    "    temp_df[\"pSjP_entropy\"] = pSjP_entropy[:200] # temp_df5[\"pSjP_entropy\"]\n",
    "        \n",
    "    # load current subject input DATA files\n",
    "    c_tState = np.load(os.path.join(model_data_output,(\"sub-\"+sid.group(0)+\"_tState.npy\")))\n",
    "    c_tProp = np.load(os.path.join(model_data_output,(\"sub-\"+sid.group(0)+\"_tProp.npy\")))\n",
    "    c_tResp = np.load(os.path.join(model_data_output,(\"sub-\"+sid.group(0)+\"_tResp.npy\")))\n",
    "    c_tTask = np.load(os.path.join(model_data_output,(\"sub-\"+sid.group(0)+\"_tTask.npy\")))\n",
    "    temp_df[\"tState\"]=c_tState[:200]\n",
    "    temp_df[\"tProp\"]=c_tProp[:200]\n",
    "    temp_df[\"tResp\"]=c_tResp[:200]\n",
    "    temp_df[\"tTask\"]=c_tTask[:200]\n",
    "    \n",
    "    # add session information\n",
    "    # sses=re.search(\"session-[0-2]{3}\", cur_DM)\n",
    "    # if sses:\n",
    "    #     temp_df[\"session\"] = int(sses.group(0)[-3:])\n",
    "    # add to df list\n",
    "    if sid.group(0) not in pilots_to_exclude:\n",
    "        DM_df_list.append(temp_df)\n",
    "        if sid.group(0) not in subjs_to_exclude:\n",
    "            DM_usable_list.append(temp_df)\n",
    "DM_df = pd.concat(DM_df_list, ignore_index=True) # merge dfs in list\n",
    "DM_df_usable = pd.concat(DM_usable_list, ignore_index=True)\n",
    "# remove no response rows (do not consider trials where no response was made)\n",
    "#DM_df = DM_df[DM_df['RT']>0]\n",
    "print(\"master data frames generated\")\n",
    "print(len(DM_df.Participant_ID.unique()), \"subjects completed the Quantum task\")\n",
    "print(len(DM_df_usable.Participant_ID.unique()), \"subjects are usable\")\n",
    "\n",
    "DM_df_usable.to_csv( os.path.join(model_data_output,(\"MASTER_dataframe__date-20250823.csv\")) )\n",
    "\n",
    "df = DM_df_usable[DM_df_usable['RT']>.199]\n",
    "df = df[df['RT']<3.5]\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbdf1b76",
   "metadata": {},
   "source": [
    "\"\"\" Brief description of computational models \"\"\"\n",
    "\n",
    "\"\"\"\n",
    "MPE MODEL\n",
    "maximum posterior estimator of joint distribution of state and hyperparameters\n",
    "\n",
    "input:\n",
    "tState: trial wise task-set (0: color 0 = face, color 1 = scene; 1: color 0 = scene, color 1 = face)\n",
    "tProp: trial-wise proportion of dots (0 - 1, for the first color)\n",
    "tResp: trial-wise response: 0 = correct, 1 = correct task wrong answer, 2 = wrong task\n",
    "\n",
    "output:\n",
    "jd: joint distribution of parameters at the end of experiment\n",
    "sE: trial-wise estimate of state, encoding probability of state 0\n",
    "tE: trial-wise estimate of task, encoding probability of task 0\n",
    "mDist: marginal distribution for the 4 thetas,\n",
    "rRange: values of the thetas\"\"\"\n",
    "\n",
    "\"\"\"\n",
    "need to re-format data for computational model ... MODIFIED 4/21/2024 to flip tTask\n",
    "tState\n",
    "  tState = np.where(cur_df['state']==-1, 1, 0)  # recode state (1 -> 0 AND -1 -> 1 ... this flip matches model better)\n",
    "tTask\n",
    "  tTask   # face=0, scene=1\n",
    "tProp\n",
    "  tProp = np.array(cur_df['amb_r']).flatten()  # set as proportion of red\n",
    "tResp\n",
    "  0=correct , 1=right task but wrong answer , 2=wrong task\n",
    "\"\"\"\n",
    "\n",
    "\"\"\"\n",
    "CONTROL MODEL(S)\n",
    "maximum posterior estimator of joint distribution of state and hyperparameters\n",
    "\n",
    "input:\n",
    "tState: trial wise task-set (0: color 0 = face, color 1 = scene; 1: color 0 = scene, color 1 = face)\n",
    "tProp: trial-wise proportion of dots (0 - 1, for the first color)\n",
    "tResp: trial-wise response: 0 = correct, 1 = correct task wrong answer, 2 = wrong task\n",
    "\n",
    "output:\n",
    "jd: joint distribution of parameters at the end of experiment\n",
    "sE: trial-wise estimate of state, encoding probability of state 0\n",
    "tE: trial-wise estimate of task, encoding probability of task 0\n",
    "mDist: marginal distribution for the 4 thetas,\n",
    "rRange: values of the thetas\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5e16300",
   "metadata": {},
   "outputs": [],
   "source": [
    "master_df_list = []\n",
    "theta_df = {'sub':[], 'lfsp':[], 'lfip':[], 'fter':[], 'ster':[], 'diff_at':[]}\n",
    "for subj_opt in df['Participant_ID'].unique():\n",
    "    # ----- load input data for this subject\n",
    "    print(\"\\nloading dataframe for subject\",str(subj_opt))\n",
    "    cur_df = pd.read_csv(os.path.join(model_data_output, 'sub-'+subj_opt+'_dataframe_3dDeconvolve_pSpP.csv'))\n",
    "    theta_df['sub'].append(subj_opt)\n",
    "    \n",
    "    # ----- load mpe model\n",
    "    with open(os.path.join(model_data_output,(\"sub-\"+subj_opt+\"_pState_pPercept_outputs.p\")), 'rb') as handle:\n",
    "        mpe_model_dict=pickle.load(handle)\n",
    "    s_jd = np.sum(mpe_model_dict['jd'], axis=0)\n",
    "    s_pRange = mpe_model_dict['pRange']\n",
    "    s_theta = [s_pRange['lfsp'][np.argmax(np.sum(s_jd,axis=(1,2,3,4)))], \n",
    "                s_pRange['lfip'][np.argmax(np.sum(s_jd,axis=(0,2,3,4)))], \n",
    "                s_pRange['fter'][np.argmax(np.sum(s_jd,axis=(0,1,3,4)))], \n",
    "                s_pRange['ster'][np.argmax(np.sum(s_jd,axis=(0,1,2,4)))], \n",
    "                s_pRange['diff_at'][np.argmax(np.sum(s_jd,axis=(0,1,2,3,)))]]\n",
    "    theta_df['lfsp'].append(s_theta[0])\n",
    "    theta_df['lfip'].append(s_theta[1])\n",
    "    theta_df['fter'].append(s_theta[2])\n",
    "    theta_df['ster'].append(s_theta[3])\n",
    "    theta_df['diff_at'].append(s_theta[4])\n",
    "    # load beliefs\n",
    "    with open(os.path.join(model_data_output,(\"sub-\"+subj_opt+\"_pSpP_belief-state.p\")), 'rb') as handle:\n",
    "        sE_belief = pickle.load(handle)\n",
    "    with open(os.path.join(model_data_output,(\"sub-\"+subj_opt+\"_pSpP_belief-task.p\")), 'rb') as handle:\n",
    "        tE_belief = pickle.load(handle)\n",
    "    with open(os.path.join(model_data_output,(\"sub-\"+subj_opt+\"_pSpP_belief-color.p\")), 'rb') as handle:\n",
    "        cE_belief = pickle.load(handle)\n",
    "    \n",
    "    # ----- load control model 1 \n",
    "    with open(os.path.join(model_data_output,(\"sub-\"+subj_opt+\"_dState_pPercept_outputs.p\")), 'rb') as handle:\n",
    "        dSpP_model_dict=pickle.load(handle)\n",
    "    c1_jd = np.sum(dSpP_model_dict['jd'], axis=0)\n",
    "    c1_pRange = dSpP_model_dict['pRange']\n",
    "    c1_theta = [c1_pRange['lfsp'][np.argmax(np.sum(c1_jd,axis=(1,2,3,4)))], \n",
    "                c1_pRange['lfip'][np.argmax(np.sum(c1_jd,axis=(0,2,3,4)))], \n",
    "                c1_pRange['fter'][np.argmax(np.sum(c1_jd,axis=(0,1,3,4)))], \n",
    "                c1_pRange['ster'][np.argmax(np.sum(c1_jd,axis=(0,1,2,4)))], \n",
    "                c1_pRange['diff_at'][np.argmax(np.sum(c1_jd,axis=(0,1,2,3,)))]]\n",
    "    # load beliefs\n",
    "    with open(os.path.join(model_data_output,(\"sub-\"+subj_opt+\"_dSpP_belief-state.p\")), 'rb') as handle:\n",
    "        dSpP_sE_belief = pickle.load(handle)\n",
    "    with open(os.path.join(model_data_output,(\"sub-\"+subj_opt+\"_dSpP_belief-task.p\")), 'rb') as handle:\n",
    "        dSpP_tE_belief = pickle.load(handle)\n",
    "    with open(os.path.join(model_data_output,(\"sub-\"+subj_opt+\"_dSpP_belief-color.p\")), 'rb') as handle:\n",
    "        dSpP_cE_belief = pickle.load(handle)\n",
    "    # add control models to master data frame\n",
    "    cur_df['dSpP_sE'] = dSpP_sE_belief[:,0]\n",
    "    cur_df['dSpP_tE'] = dSpP_tE_belief[:]\n",
    "    cur_df['dSpP_cE'] = dSpP_cE_belief[:]\n",
    "    \n",
    "    # ----- load control model 2 \n",
    "    with open(os.path.join(model_data_output,(\"sub-\"+subj_opt+\"_pState_dPercept_outputs.p\")), 'rb') as handle:\n",
    "        pSdP_model_dict=pickle.load(handle)\n",
    "    c2_jd = np.sum(pSdP_model_dict['jd'], axis=0)\n",
    "    c2_pRange = pSdP_model_dict['pRange']\n",
    "    c2_theta = [c2_pRange['lfsp'][np.argmax(np.sum(c2_jd,axis=(1,2,3,4)))], \n",
    "                c2_pRange['lfip'][np.argmax(np.sum(c2_jd,axis=(0,2,3,4)))], \n",
    "                c2_pRange['fter'][np.argmax(np.sum(c2_jd,axis=(0,1,3,4)))], \n",
    "                c2_pRange['ster'][np.argmax(np.sum(c2_jd,axis=(0,1,2,4)))], \n",
    "                c2_pRange['diff_at'][np.argmax(np.sum(c2_jd,axis=(0,1,2,3,)))]]\n",
    "    # load beliefs\n",
    "    with open(os.path.join(model_data_output,(\"sub-\"+subj_opt+\"_pSdP_belief-state.p\")), 'rb') as handle:\n",
    "        pSdP_sE_belief = pickle.load(handle)\n",
    "    with open(os.path.join(model_data_output,(\"sub-\"+subj_opt+\"_pSdP_belief-task.p\")), 'rb') as handle:\n",
    "        pSdP_tE_belief = pickle.load(handle)\n",
    "    with open(os.path.join(model_data_output,(\"sub-\"+subj_opt+\"_pSdP_belief-color.p\")), 'rb') as handle:\n",
    "        pSdP_cE_belief = pickle.load(handle)\n",
    "    # add control models to master data frame\n",
    "    cur_df['pSdP_sE'] = pSdP_sE_belief[:,0]\n",
    "    cur_df['pSdP_tE'] = pSdP_tE_belief[:]\n",
    "    cur_df['pSdP_cE'] = pSdP_cE_belief[:]\n",
    "    \n",
    "    # ----- load control model 3 \n",
    "    with open(os.path.join(model_data_output,(\"sub-\"+subj_opt+\"_dState_dPercept_outputs.p\")), 'rb') as handle:\n",
    "        dSdP_model_dict=pickle.load(handle)\n",
    "    c3_jd = np.sum(dSdP_model_dict['jd'], axis=0)\n",
    "    c3_pRange = dSdP_model_dict['pRange']\n",
    "    c3_theta = [c3_pRange['lfsp'][np.argmax(np.sum(c3_jd,axis=(1,2,3,4)))], \n",
    "                c3_pRange['lfip'][np.argmax(np.sum(c3_jd,axis=(0,2,3,4)))], \n",
    "                c3_pRange['fter'][np.argmax(np.sum(c3_jd,axis=(0,1,3,4)))], \n",
    "                c3_pRange['ster'][np.argmax(np.sum(c3_jd,axis=(0,1,2,4)))], \n",
    "                c3_pRange['diff_at'][np.argmax(np.sum(c3_jd,axis=(0,1,2,3,)))]]\n",
    "    # load beliefs\n",
    "    with open(os.path.join(model_data_output,(\"sub-\"+subj_opt+\"_dSdP_belief-state.p\")), 'rb') as handle:\n",
    "        dSdP_sE_belief = pickle.load(handle)\n",
    "    with open(os.path.join(model_data_output,(\"sub-\"+subj_opt+\"_dSdP_belief-task.p\")), 'rb') as handle:\n",
    "        dSdP_tE_belief = pickle.load(handle)\n",
    "    with open(os.path.join(model_data_output,(\"sub-\"+subj_opt+\"_dSdP_belief-color.p\")), 'rb') as handle:\n",
    "        dSdP_cE_belief = pickle.load(handle)\n",
    "    # add control models to master data frame\n",
    "    cur_df['dSdP_sE'] = dSdP_sE_belief[:,0]\n",
    "    cur_df['dSdP_tE'] = dSdP_tE_belief[:]\n",
    "    cur_df['dSdP_cE'] = dSdP_cE_belief[:]\n",
    "    \n",
    "    \n",
    "    # add control models to master data frame\n",
    "    cur_df['sub'] = subj_opt\n",
    "    master_df_list.append(cur_df)\n",
    "    \n",
    "\n",
    "    # -- theta parameters for mpe model\n",
    "    pRange_keys = ['lfsp', 'lfip', 'fter', 'ster', 'diff_at']\n",
    "    pRange_titles = {'lfsp':'slope param', 'lfip':'intercept param', 'fter':'face error param', 'ster':'scene error param', 'diff_at':'diffusion param'}\n",
    "    x_ranges = [[1.5, 5], [-3.0, 3.0], [0.0, 0.35], [0.0, 0.35], [0.0, 0.9]]\n",
    "    pRange_colors = ['deepskyblue','steelblue','orange','green','red'] # set colors so I know what is what\n",
    "    pRange = mpe_model_dict['pRange']\n",
    "    mDist = mpe_model_dict['mDist']\n",
    "    plt.rcParams[\"figure.figsize\"] = (40,10)\n",
    "    fig_thetas, ax_thetas = plt.subplots(1,5)\n",
    "    for ind, cur_key in enumerate(pRange_keys):\n",
    "        ax_thetas[ind].set_xlim(x_ranges[ind][0],x_ranges[ind][1])\n",
    "        ax_thetas[ind].set_yticklabels([])\n",
    "        ax_thetas[ind].plot(pRange[cur_key], mDist[cur_key], color=pRange_colors[ind])\n",
    "        ax_thetas[ind].set_title(pRange_titles[cur_key])\n",
    "    plt.show()\n",
    "    plt.savefig(os.path.join(model_data_output,(\"sub-\"+subj_opt+\"_model-pSpP__thetas.png\")))\n",
    "    plt.close()\n",
    "\n",
    "master_df = pd.concat(master_df_list, ignore_index=True) # merge dfs in list\n",
    "\n",
    "# # ----- save out master data frames\n",
    "master_df.to_csv(os.path.join(model_data_output, 'sub-'+subj_opt+'_master_dataframe_allmodels.csv'))\n",
    "theta_df = pd.DataFrame(theta_df)\n",
    "theta_df.to_csv(os.path.join(model_data_output, 'sub-'+subj_opt+'_master_dataframe_thetas.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56793929",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---- create model plots\n",
    "for subj_opt in df['Participant_ID'].unique():\n",
    "    # ----- load input data for this subject\n",
    "    print(\"\\nloading files for subject\",str(subj_opt))\n",
    "    # load current subject input DATA files\n",
    "    c_tState = np.load(os.path.join(model_data_output,(\"sub-\"+subj_opt+\"_tState.npy\")))\n",
    "    c_tProp = np.load(os.path.join(model_data_output,(\"sub-\"+subj_opt+\"_tProp.npy\")))\n",
    "    c_tResp = np.load(os.path.join(model_data_output,(\"sub-\"+subj_opt+\"_tResp.npy\")))\n",
    "    c_tTask = np.load(os.path.join(model_data_output,(\"sub-\"+subj_opt+\"_tTask.npy\")))\n",
    "    cur_df = pd.read_csv(os.path.join(model_data_output, 'sub-'+subj_opt+'_dataframe_3dDeconvolve_pSpP.csv'))\n",
    "    # also set up binary color variable\n",
    "    c_tProp_bin = c_tProp.round()\n",
    "    \n",
    "    # ----- make plots\n",
    "    sE_belief = cur_df['pSpP_sE']\n",
    "    tE_belief = cur_df['pSpP_tE']\n",
    "    cE_belief = cur_df['pSpP_cE']\n",
    "    \n",
    "    t_belief_alpha = 0.5\n",
    "    c_belief_alpha = 0.5\n",
    "    # -- model estimates\n",
    "    c_sE = 1 - sE_belief[:200] # [:,1] = probability state 1\n",
    "    c_tE = 1 - tE_belief[:200] # 1 - tE ... because tE = probability task 0 ... we want probability task 1\n",
    "    c_cE = cE_belief[:200]\n",
    "    gen_model_plots(c_tState[:200], c_tTask[:200], c_tProp[:200], c_sE[:200], c_tE[:200], c_cE[:200], os.path.join(model_data_output,(subj_opt+\"_param-ModelEstimates_model-pSpP.png\")), c_tResp[:200], t_belief_alpha, c_belief_alpha)\n",
    "    \n",
    "    t_belief_alpha = 0.15\n",
    "    c_belief_alpha = 0.5\n",
    "    # -- prediction error\n",
    "    c_sE = np.abs(c_tState[:200] - (1 - sE_belief[:200])) # [:,1] = probability state 1\n",
    "    c_tE = np.abs(c_tTask[:200] - (1 - tE_belief[:200]))  # 1 - tE ... because tE = probability task 0 ... we want probability task 1\n",
    "    c_cE = np.abs(c_tProp_bin[:200] - cE_belief[:200])\n",
    "    gen_model_plots(c_tState[:200], c_tTask[:200], c_tProp[:200], c_sE[:200], c_tE[:200], c_cE[:200], os.path.join(model_data_output,(subj_opt+\"_param-PredictionError_model-pSpP.png\")), c_tResp[:200], t_belief_alpha, c_belief_alpha)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f4d0296",
   "metadata": {},
   "source": [
    "Code below this sets up and then generates the PREDICTION ACCURACY and BIC plots\n",
    "----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23dc062f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "CODE FOR CALCULATING MODEL FIT\n",
    "...\n",
    "\"\"\"\n",
    "\n",
    "master_df = DM_df_usable # all trials\n",
    "master_df_reduced = df # trials with  200ms <= RTs <= 3500ms\n",
    "\n",
    "df_to_use = master_df\n",
    "\n",
    "# get the actual task performed \n",
    "taskPerformed = []\n",
    "for trl, resp in enumerate(df_to_use[\"tResp\"]):\n",
    "    if resp==2:\n",
    "        taskPerformed.append(1-df_to_use[\"tTask\"][trl])\n",
    "    else:\n",
    "        taskPerformed.append(df_to_use[\"tTask\"][trl])\n",
    "df_to_use[\"taskPerformed\"] = taskPerformed\n",
    "\n",
    "# get subject level prediction accuracy\n",
    "subList = []\n",
    "pSpP = []\n",
    "dSpP = []\n",
    "pSdP = []\n",
    "dSdP = []\n",
    "pSjP = []\n",
    "for subj_opt in df_to_use[\"Participant_ID\"].unique():\n",
    "    subList.append(subj_opt)\n",
    "    sub_df = df_to_use[df_to_use[\"Participant_ID\"]==subj_opt]\n",
    "    pSpP.append(sum(sub_df[\"taskPerformed\"]==sub_df[\"pSpP_tE\"].round()))\n",
    "    dSpP.append(sum(sub_df[\"taskPerformed\"]==sub_df[\"dSpP_tE\"].round()))\n",
    "    pSdP.append(sum(sub_df[\"taskPerformed\"]==sub_df[\"pSdP_tE\"].round()))\n",
    "    dSdP.append(sum(sub_df[\"taskPerformed\"]==sub_df[\"dSdP_tE\"].round()))\n",
    "    pSjP.append(sum(sub_df[\"taskPerformed\"]==sub_df[\"pSjP_tE\"].round()))\n",
    "    \n",
    "    print(\"pSpP prediction err for subject \", subj_opt, \" is \", sum(sub_df[\"taskPerformed\"]==sub_df[\"pSpP_tE\"].round())) #, \"  \", sum(taskPerformed==pSpP_tE_v2_binary), \"  \", sum(taskPerformed==pSpP_tE_v3_binary), \"  \", sum(taskPerformed==pSpP_tE_v4_binary))\n",
    "    print(\"dSpP prediction err for subject \", subj_opt, \" is \", sum(sub_df[\"taskPerformed\"]==sub_df[\"dSpP_tE\"].round()))\n",
    "    print(\"pSdP prediction err for subject \", subj_opt, \" is \", sum(sub_df[\"taskPerformed\"]==sub_df[\"pSdP_tE\"].round()))\n",
    "    print(\"dSdP prediction err for subject \", subj_opt, \" is \", sum(sub_df[\"taskPerformed\"]==sub_df[\"dSdP_tE\"].round()))\n",
    "    print(\"pSjP prediction err for subject \", subj_opt, \" is \", sum(sub_df[\"taskPerformed\"]==sub_df[\"pSjP_tE\"].round()))\n",
    "\n",
    "tmp_df = pd.DataFrame({'sub':subList, \n",
    "                       'pSpP':pSpP, \n",
    "                       'dSpP':dSpP, \n",
    "                       'pSdP':pSdP, \n",
    "                       'dSdP':dSdP,\n",
    "                       'pSjP':pSjP})\n",
    "tmp_df.to_csv(os.path.join(model_data_output, \"prediction_error_by_model__date-20250823.csv\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e1a2615",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -- plot of prediction accuracy\n",
    "plot_df = tmp_df.melt(\"sub\")\n",
    "plot_df[\"value\"] = plot_df[\"value\"]/200\n",
    "plot_df.columns = [\"sub\", \"Models\", \"Prediction Error\"]\n",
    "# -- prediction accuracy plots\n",
    "sns.set(rc={'figure.figsize':(8,6)}, font_scale=1.75)\n",
    "ax = plt.figure(figsize=(8,12))\n",
    "#ax = sns.boxplot(data=plot_df, x=\"variable\", y=\"value\", ) \n",
    "#ax = sns.violinplot(data=plot_df, x=\"variable\", y=\"value\", inner=\"point\")\n",
    "#sns.catplot(data=plot_df, x=\"Models\", y=\"Prediction Error\", kind=\"violin\", inner=\"quart\", ylim=(0,1)) #, ax = ax) #, inner=None)\n",
    "#sns.swarmplot(data=plot_df, x=\"Models\", y=\"Prediction Error\", color='w', size=3, facet_kws={ylim:(0,1)})\n",
    "\n",
    "g = sns.catplot(data=plot_df, x=\"Models\", y=\"Prediction Error\", kind=\"violin\", height=6, aspect=1.5, inner=\"quart\", palette=\"tab10\", saturation=0.5)\n",
    "g = sns.swarmplot(data=plot_df, x=\"Models\", y=\"Prediction Error\", dodge=True, color='w', size=4)\n",
    "g.set(ylim=(0,0.75))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ea23eb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "bic_df = pd.read_csv(os.path.join(model_data_output,(\"38subjs__logit_PE-binary_BIC_cross-valid.csv\"))) # 38subjs__logit_PE-continuous_BIC_cross-valid.csv\n",
    "# -- plot of BIC\n",
    "plot_df = bic_df.melt(\"Unnamed: 0\")\n",
    "#plot_df[\"value\"] = plot_df[\"value\"]/200\n",
    "plot_df.columns = [\"sub\", \"Models\", \"BIC\"]\n",
    "# -- BIC plots\n",
    "sns.set(rc={'figure.figsize':(8,6)}, font_scale=1.75)\n",
    "ax = plt.figure(figsize=(8,12))\n",
    "#ax = sns.boxplot(data=plot_df, x=\"variable\", y=\"value\", ) \n",
    "#ax = sns.violinplot(data=plot_df, x=\"variable\", y=\"value\", inner=\"point\")\n",
    "#sns.catplot(data=plot_df, x=\"Models\", y=\"Prediction Error\", kind=\"violin\", inner=\"quart\", ylim=(0,1)) #, ax = ax) #, inner=None)\n",
    "#sns.swarmplot(data=plot_df, x=\"Models\", y=\"Prediction Error\", color='w', size=3, facet_kws={ylim:(0,1)})\n",
    "\n",
    "g = sns.catplot(data=plot_df, x=\"Models\", y=\"BIC\", kind=\"violin\", height=6, aspect=1.5, inner=\"quart\", palette=\"tab10\", saturation=0.75)\n",
    "g = sns.swarmplot(data=plot_df, x=\"Models\", y=\"BIC\", dodge=True, color='w', size=4)\n",
    "#g.set(ylim=(0,0.75))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28d5f8c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---- subject by subject breakdown of BIC scores\n",
    "plot_df.BIC.round(2)\n",
    "plot_df['Models'] = pd.Categorical(plot_df['Models'], categories=[\"pSpP\", \"dSpP\", \"pSdP\", \"dSdP\", \"pSjP\"], ordered=True)\n",
    "plot_df = plot_df.sort_values('Models')\n",
    "\n",
    "heatmap_data = plot_df.pivot_table(index='sub', columns='Models', values='BIC')\n",
    "\n",
    "plt.figure(figsize=(60, 40))\n",
    "sns.heatmap(heatmap_data, annot=True, fmt='g', cmap='viridis', vmin=80, vmax=250)\n",
    "plt.title('Heatmap of BIC scores by subject')\n",
    "plt.show()\n",
    "#Explanation:\n",
    "#df.pivot_table(index='Category_A', columns='Category_B', values='Value'):\n",
    "#This crucial step transforms your \"long-form\" data into a \"wide-form\" matrix suitable for a heatmap. Category_A becomes the index (rows), Category_B becomes the columns, and the Value column provides the aggregated data for each cell.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc083ae3",
   "metadata": {},
   "source": [
    "Set up fMRI plot variables\n",
    "----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b562a33c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --------------------------------------------------------------------------------------------------------------------------\n",
    "# - - - - - - - - - - - - - - - - - - - - - - - - - - - - -\n",
    "# - - - -    Set up Some Variables for fMRI Plots   - - - -\n",
    "# - - - - - - - - - - - - - - - - - - - - - - - - - - - - -\n",
    "#Load cortical surface mesh\n",
    "fsaverage = datasets.fetch_surf_fsaverage()\n",
    "#load atlas\n",
    "atlas_data = datasets.fetch_atlas_schaefer_2018(n_rois=400, yeo_networks=17, resolution_mm=2) # fetch_atlas_yeo_2011()\n",
    "atlas = atlas_data.maps\n",
    "atlas_labels = atlas_data.labels\n",
    "networks = []\n",
    "for ii in range(len(atlas_labels)-1):\n",
    "    networks.append(atlas_labels[ii+1].split(\"_\")[2])\n",
    "\n",
    "#project atlas onto fsaverage\n",
    "fsaverage = datasets.fetch_surf_fsaverage('fsaverage')\n",
    "textures=[]\n",
    "textures.append(surface.vol_to_surf(atlas, fsaverage['pial_left'], inner_mesh=fsaverage['white_left'], interpolation='nearest', n_samples=1, radius=0.0))\n",
    "textures.append(surface.vol_to_surf(atlas, fsaverage['pial_left'], inner_mesh=fsaverage['white_left'], interpolation='nearest', n_samples=1, radius=0.0))\n",
    "textures.append(surface.vol_to_surf(atlas, fsaverage['pial_right'], inner_mesh=fsaverage['white_right'], interpolation='nearest', n_samples=1, radius=0.0))\n",
    "textures.append(surface.vol_to_surf(atlas, fsaverage['pial_right'], inner_mesh=fsaverage['white_right'], interpolation='nearest', n_samples=1, radius=0.0))\n",
    "\n",
    "# -- set up rois as 17 networks (remove specific roi info\n",
    "n_color_dict = {'ContA':'indianred',\n",
    "                'ContB':'firebrick',\n",
    "                'ContC':'maroon',\n",
    "                'DefaultA':'royalblue',\n",
    "                'DefaultB':'mediumblue',\n",
    "                'DefaultC':'navy',\n",
    "                'DorsAttnA':'forestgreen',\n",
    "                'DorsAttnB':'darkgreen',\n",
    "                'LimbicA':'lightyellow',\n",
    "                'LimbicB':'beige',\n",
    "                'SalVentAttnA':'darkorchid',\n",
    "                'SalVentAttnB':'mediumorchid',\n",
    "                'SomMotA':'saddlebrown',\n",
    "                'SomMotB':'sienna',\n",
    "                'TempPar':'peachpuff',\n",
    "                'VisCent':'lightgrey',\n",
    "                'VisPeri':'darkgrey'}\n",
    "n_textures=[]\n",
    "n_textures.append(np.zeros(len(textures[0])))\n",
    "n_textures.append(np.zeros(len(textures[1])))\n",
    "n_textures.append(np.zeros(len(textures[2])))\n",
    "n_textures.append(np.zeros(len(textures[3])))\n",
    "custom_color_list = []\n",
    "for n_idx, c_network in enumerate(sorted(list(set(networks)))):\n",
    "    custom_color_list.append(n_color_dict[c_network])\n",
    "    matching_indices = [index for index, value in enumerate(networks) if value == c_network]\n",
    "    for idx, ctext in enumerate(textures):\n",
    "        n_textures[idx][np.isin(ctext,matching_indices)] = n_idx+1.0\n",
    "# -- set up custom color map for networks\n",
    "discrete_cmap = mcolors.ListedColormap(custom_color_list)\n",
    "\n",
    "# load the Schaefer 2018 atlas (400 ROIs)\n",
    "atlas_img = nib.load(atlas)\n",
    "roi_labels = atlas_data.labels  # list of 400 ROI labels\n",
    "roi_indices = np.arange(1, 401)  # assuming atlas labels are 1-indexed\n",
    "# Use NiftiLabelsMasker with the Schaefer atlas to extract ROI betas.\n",
    "masker = NiftiLabelsMasker(labels_img=atlas_img, standardize=False)\n",
    "resampled_atlas_img = resample_img(atlas_img, target_affine=cortical_mask.affine, target_shape=cortical_mask_data.shape, interpolation='nearest', force_resample=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee1ea216",
   "metadata": {},
   "source": [
    "Section 2\n",
    "\n",
    "# ------------------------------------------------------------------------------------------\n",
    "# - - - - - - - - - - - - - - - - -\n",
    "# - -   Parametric Modulation   - -\n",
    "# - - - - - - - - - - - - - - - - -"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3d8363a",
   "metadata": {},
   "outputs": [],
   "source": [
    "PM_path = os.path.join(dataset_dir, \"3dMEMA\")\n",
    "\n",
    "# - - - - lists for loading my own data\n",
    "mask_list = [\"cue_zEntropy_masked.BRIK\",\n",
    "             \"feedback_zTaskPE_masked.BRIK\",\n",
    "             \"feedback_zStatePE_masked.BRIK\",\n",
    "             \"feedback_zColorPE_masked.BRIK\",\n",
    "             \"cue_stateD_masked.BRIK\",\n",
    "             \"cue_zState_masked.BRIK\"]\n",
    "model_list = [\"cue__zEntropy_SPMGmodel_stats_REML__tval.nii.gz\",\n",
    "              \"feedback__zTaskPE_SPMGmodel_stats_REML__tval.nii.gz\",\n",
    "              \"feedback__zStatePE_SPMGmodel_stats_REML__tval.nii.gz\",\n",
    "              \"feedback__zColorPE_SPMGmodel_stats_REML__tval.nii.gz\",\n",
    "              \"cue__StateD_SPMGmodel_stats_REML__tval.nii.gz\",\n",
    "              \"cue__zState_SPMGmodel_stats_REML__tval.nii.gz\"]\n",
    "vmin_list = [-6, -6, -6, -6, -6, -6]\n",
    "vmax_list = [6, 6, 6, 6, 6, 6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7292811",
   "metadata": {},
   "outputs": [],
   "source": [
    "# - - - - - - - - -\n",
    "# plot all 17 networks together\n",
    "# - - - - - - - - -\n",
    "for m_idx, c_model in enumerate(model_list):\n",
    "    # -- load current stat image sig clusters mask\n",
    "    brik_mask = nib.load(os.path.join(PM_path, \"nii3D\", mask_list[m_idx])) # load sig rois for state or color\n",
    "    brik_data = brik_mask.get_fdata()\n",
    "    roi_data = np.where(np.squeeze(brik_data)>1,1,0) # binarize just in case its not already    \n",
    "    roi_data = np.where(np.squeeze(cortical_mask_data)>0,roi_data,0) # apply cortical mask too\n",
    "    mask_img = nib.Nifti1Image(roi_data, brik_mask.affine, brik_mask.header)\n",
    "    \n",
    "    stat_img0 = nib.load(os.path.join(PM_path, \"nii3D\", c_model))\n",
    "    stat_masked = nilearn.masking.apply_mask(stat_img0, mask_img)\n",
    "    stat_img = masking.unmask(stat_masked, mask_img)\n",
    "    print(\"cur stat: \", os.path.join(PM_path, \"nii3D\", c_model))\n",
    "    \n",
    "    stat_img_list = []\n",
    "    stat_img_list.append(surface.vol_to_surf(stat_img, fsaverage['pial_left']))\n",
    "    stat_img_list.append(surface.vol_to_surf(stat_img, fsaverage['pial_left'], inner_mesh=fsaverage['white_left']))\n",
    "    stat_img_list.append(surface.vol_to_surf(stat_img, fsaverage['pial_right'], inner_mesh=fsaverage['white_right']))\n",
    "    stat_img_list.append(surface.vol_to_surf(stat_img, fsaverage['pial_right']))\n",
    "    \n",
    "    # ------------------ plot sagital surface plots w/ 17 networks ------------------ #\n",
    "    figures, axes = plt.subplots(figsize=(25,25),nrows=1,ncols=4,subplot_kw={'projection': '3d'},sharex=True,sharey=True)\n",
    "    figures.suptitle(c_network, fontsize=16)\n",
    "    \n",
    "    # plot atlas \n",
    "    plotting.plot_surf_roi(fsaverage.pial_left, colorbar=False, roi_map=n_textures[0], hemi='left', view='lateral',\n",
    "                        darkness=0.3, cmap=discrete_cmap, bg_on_data=True, bg_map=fsaverage.sulc_left, axes=axes[0])\n",
    "    plotting.plot_surf_roi(fsaverage.pial_left, colorbar=False, roi_map=n_textures[1], hemi='left', view='medial',\n",
    "                        darkness=0.3, cmap=discrete_cmap, bg_on_data=True, bg_map=fsaverage.sulc_left, axes=axes[1])\n",
    "    plotting.plot_surf_roi(fsaverage.pial_right, colorbar=False, roi_map=n_textures[2], hemi='right', view='medial',\n",
    "                        darkness=0.3, cmap=discrete_cmap, bg_on_data=True, bg_map=fsaverage.sulc_right, axes=axes[2])\n",
    "    plotting.plot_surf_roi(fsaverage.pial_right, colorbar=False, roi_map=n_textures[3], hemi='right', view='lateral',\n",
    "                        darkness=0.3, cmap=discrete_cmap, bg_on_data=True, bg_map=fsaverage.sulc_right, axes=axes[3])\n",
    "    \n",
    "    # #plot maps\n",
    "    # plotting.plot_surf_stat_map(fsaverage.pial_left, colorbar=False, stat_map=stat_img_list[0], bg_map=fsaverage.sulc_left, hemi='left', view='lateral',\n",
    "    #                         darkness=0.1, alpha=0.005, axes=axes[0], threshold=2.985, vmin=-10, vmax=10)\n",
    "    # plotting.plot_surf_stat_map(fsaverage.pial_left, colorbar=False, stat_map=stat_img_list[1], bg_map=fsaverage.sulc_left, hemi='left', view='medial',\n",
    "    #                         darkness=0.1, alpha=0.005, axes=axes[1], threshold=2.985, vmin=-10, vmax=10)\n",
    "    # plotting.plot_surf_stat_map(fsaverage.pial_right, colorbar=False, stat_map=stat_img_list[2], bg_map=fsaverage.sulc_right, hemi='right', view='medial',\n",
    "    #                         darkness=0.1, alpha=0.005, axes=axes[2], threshold=2.985, vmin=-10, vmax=10)\n",
    "    # plotting.plot_surf_stat_map(fsaverage.pial_right, colorbar=False, stat_map=stat_img_list[3], bg_map=fsaverage.sulc_right, hemi='right', view='lateral',\n",
    "    #                         darkness=0.1, alpha=0.005, axes=axes[3], threshold=2.985, vmin=-10, vmax=10)\n",
    "    \n",
    "    figures.subplots_adjust(wspace=0.01,hspace=0.00)\n",
    "    figures.savefig(os.path.join(PM_path,\"nilearn_plots\", (\"17networks_\"+c_model[:-34]+'.png')), bbox_inches='tight')\n",
    "    plt.show() # plt.close('all')\n",
    "    \"c\"+2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68548015",
   "metadata": {},
   "outputs": [],
   "source": [
    "# - - - - - - - - -\n",
    "# bar plots of number of clusters in each network\n",
    "# - - - - - - - - -\n",
    "# mask_list = [\"feedback_zTaskPE_masked.BRIK\",\n",
    "#              \"feedback_zStatePE_masked.BRIK\",\n",
    "#              \"feedback_zColorPE_masked.BRIK\",\n",
    "#              \"cue_stateD_masked.BRIK\",\n",
    "#              \"cue_zState_masked.BRIK\",\n",
    "#              \"cue_zEntropy_masked.BRIK\"]\n",
    "# loop through each sig roi mask\n",
    "for m_idx, c_mask in enumerate(mask_list):\n",
    "    if c_mask==\"feedback_zTaskPE_masked.BRIK\":\n",
    "        sns.set(rc={'figure.figsize':(5.5, 3.25)}) # width=10 inches, height=6 inches\n",
    "    elif c_mask==\"feedback_zStatePE_masked.BRIK\":\n",
    "        sns.set(rc={'figure.figsize':(5.5, 3.25)}) # width=10 inches, height=6 inches\n",
    "    elif c_mask==\"cue_stateD_masked.BRIK\":\n",
    "        sns.set(rc={'figure.figsize':(5.5, 3.25)}) # width=10 inches, height=6 inches\n",
    "    elif c_mask==\"feedback_zColorPE_masked.BRIK\":\n",
    "        sns.set(rc={'figure.figsize':(5.5, 9)})\n",
    "    else:\n",
    "        sns.set(rc={'figure.figsize':(5.5, 3.75)}) # width=10 inches, height=6 inches\n",
    "    print(\"working with \", c_mask)\n",
    "    # -- set up dict to save rois per network for bar plots\n",
    "    results_dict = {'ContA':0, 'ContB':0, 'ContC':0,\n",
    "                'DefaultA':0, 'DefaultB':0, 'DefaultC':0,\n",
    "                'DorsAttnA':0, 'DorsAttnB':0,\n",
    "                'LimbicA':0, 'LimbicB':0,\n",
    "                'SalVentAttnA':0, 'SalVentAttnB':0,\n",
    "                'SomMotA':0, 'SomMotB':0,\n",
    "                'TempPar':0,\n",
    "                'VisCent':0, 'VisPeri':0}\n",
    "    total_voxel_count = 0\n",
    "    # -- load current stat image sig clusters mask\n",
    "    stat_img0 = nib.load(os.path.join(PM_path, \"nii3D\", model_list[m_idx]))\n",
    "    brik_mask = nib.load(os.path.join(PM_path, \"nii3D\", c_mask)) # load sig rois for state or color\n",
    "    brik_data = brik_mask.get_fdata()\n",
    "    print(\"number of rois in current mask: \", int(brik_data.max()))\n",
    "    for roi in range(int(brik_data.max())):\n",
    "        # -- set sig roi cluster mask\n",
    "        sig_clust_data = np.where(np.squeeze(brik_data)==(roi+1),1,0) # binarize current roi\n",
    "        sig_clust_data = np.where(np.squeeze(cortical_mask_data)>0,sig_clust_data,0) # apply cortical mask too\n",
    "        sig_clust_img = nib.Nifti1Image(sig_clust_data, brik_mask.affine, brik_mask.header)\n",
    "        \n",
    "        try:\n",
    "            # mask stats data to see if cluster is pos or neg\n",
    "            stat_masked = nilearn.masking.apply_mask(stat_img0, sig_clust_img)\n",
    "            if stat_masked.mean() < 0:\n",
    "                continue # skip this roi if it is negative\n",
    "            # -- mask atals data so we can see which networks this cluster overlaps with\n",
    "            atlas_masked = nilearn.masking.apply_mask(resampled_atlas_img, sig_clust_img)\n",
    "            atlas_masked = atlas_masked[atlas_masked>0] # only use voxels with atlas labels so it all sums to 1\n",
    "        except:\n",
    "            print(\"error probably due to no data after masking.. just move on and skip this roi\")\n",
    "            continue\n",
    "        \n",
    "        #num_voxels_w_roi_labels = atlas_masked.shape \n",
    "        # -- okay pull networks that match rois with data\n",
    "        c_networks_list = [networks[(i-1)] for i in atlas_masked.astype(int)]\n",
    "        for c_net in c_networks_list:\n",
    "            results_dict[c_net] += 1 # add 1 to show 1 voxel overlapped with this sig cluster\n",
    "            total_voxel_count += 1\n",
    "    \n",
    "    for net_key in results_dict.keys():\n",
    "        results_dict[net_key] = results_dict[net_key] / total_voxel_count\n",
    "    \n",
    "    results_df = pd.DataFrame(results_dict, index=[0])\n",
    "    melt_df = pd.melt(results_df)\n",
    "    #print(melt_df)\n",
    "    sns.barplot(x='variable', y='value', data=melt_df, palette=custom_color_list, edgecolor='black', linewidth=1.5)\n",
    "    plt.title(c_mask[:-11] + \"\\n\")\n",
    "    plt.xlabel(\"Network\")\n",
    "    plt.xticks(rotation=45, ha='right')\n",
    "    plt.ylabel(\"Proportion of sig. voxels\\noverlapping with network\")\n",
    "    if c_mask==\"feedback_zTaskPE_masked.BRIK\":\n",
    "        plt.ylim((0,0.3))\n",
    "    elif c_mask==\"feedback_zStatePE_masked.BRIK\":\n",
    "        plt.ylim((0,0.3))\n",
    "    elif c_mask==\"feedback_zColorPE_masked.BRIK\":\n",
    "        plt.ylim((0,0.99))\n",
    "    elif c_mask==\"cue_stateD_masked.BRIK\":\n",
    "        plt.ylim((0,0.3))\n",
    "    else:\n",
    "        plt.ylim((0,0.45))\n",
    "    \n",
    "    plt.savefig(os.path.join(PM_path,\"nilearn_plots\",(\"17networks__bar_plot__\"+c_mask[:-11]+\".png\")), bbox_inches='tight')\n",
    "    \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a80ddc93",
   "metadata": {},
   "outputs": [],
   "source": [
    "vox_thresh = 2.026 \n",
    "for m_idx, c_model in enumerate(model_list):\n",
    "    # -- load current stat image sig clusters mask\n",
    "    brik_mask = nib.load(os.path.join(PM_path, \"nii3D\", mask_list[m_idx])) # load sig rois for state or color\n",
    "    brik_data = brik_mask.get_fdata()\n",
    "    roi_data = np.where(np.squeeze(brik_data)>0,1,0) # binarize just in case its not already    \n",
    "    roi_data = np.where(np.squeeze(cortical_mask_data)>0,roi_data,0) # apply cortical mask too\n",
    "    mask_img = nib.Nifti1Image(roi_data, brik_mask.affine, brik_mask.header)\n",
    "    \n",
    "    stat_img0 = nib.load(os.path.join(PM_path, \"nii3D\", c_model))\n",
    "    stat_masked = nilearn.masking.apply_mask(stat_img0, mask_img)\n",
    "    stat_img = masking.unmask(stat_masked, mask_img)\n",
    "    print(\"cur stat: \", os.path.join(PM_path, \"nii3D\", c_model))\n",
    "    \n",
    "    # if c_model == \"cue__StateD_SPMGmodel_stats_REML__tval\":\n",
    "    #     cut_cords_list = [[-15], [-6, -3], [6, 15], [30, 42, 48]] #left-medial, right-medial, left-lateral, right-lateral\n",
    "    # else:\n",
    "    #     cut_cords_list = [[-15], [-6, -3], [3, 12, 18], [39, 48, 54]]\n",
    "    cut_cords_list = [[-16, -11, -9, -2], [1, 6, 17], [20, 23, 32], [42, 52, 64]]\n",
    "\n",
    "    # # ------------------ plot axial slices ------------------ #\n",
    "    L_sag_cuts = plotting.plot_stat_map(stat_map_img=stat_img, threshold=vox_thresh, cmap=plt.cm.RdBu_r, display_mode='z', cut_coords=cut_cords_list[0], vmin=vmin_list[m_idx], vmax=vmax_list[m_idx])\n",
    "    L_sag_cuts.savefig(os.path.join(PM_path,\"nilearn_plots\", (c_model[:-34]+'__Inferior_Ax-1.png')))\n",
    "    plt.show() # plt.close('all')\n",
    "    R_sag_cuts = plotting.plot_stat_map(stat_map_img=stat_img, threshold=vox_thresh, cmap=plt.cm.RdBu_r, display_mode='z', cut_coords=cut_cords_list[1], vmin=vmin_list[m_idx], vmax=vmax_list[m_idx])\n",
    "    R_sag_cuts.savefig(os.path.join(PM_path,\"nilearn_plots\", (c_model[:-34]+'__Inferior_Ax-2.png')))\n",
    "    plt.show() # plt.close('all')\n",
    "    \n",
    "    L_sag_cuts = plotting.plot_stat_map(stat_map_img=stat_img, threshold=vox_thresh, cmap=plt.cm.RdBu_r, display_mode='z', cut_coords=cut_cords_list[2], vmin=vmin_list[m_idx], vmax=vmax_list[m_idx])\n",
    "    L_sag_cuts.savefig(os.path.join(PM_path,\"nilearn_plots\", (c_model[:-34]+'__Superior_Ax-1.png')))\n",
    "    plt.show() # plt.close('all')\n",
    "    R_sag_cuts = plotting.plot_stat_map(stat_map_img=stat_img, threshold=vox_thresh, cmap=plt.cm.RdBu_r, display_mode='z', cut_coords=cut_cords_list[3], vmin=vmin_list[m_idx], vmax=vmax_list[m_idx])\n",
    "    R_sag_cuts.savefig(os.path.join(PM_path,\"nilearn_plots\", (c_model[:-34]+'__Superior_Ax-2.png')))\n",
    "    plt.show() # plt.close('all')\n",
    "\n",
    "    # figures, axes = plt.subplots(figsize=(25,25),nrows=1,ncols=4,subplot_kw={'projection': '3d'},sharex=True,sharey=True)\n",
    "\n",
    "    # ------------------ plot sagital surface plots ------------------ #\n",
    "    stat_img_list = []\n",
    "    stat_img_list.append(surface.vol_to_surf(stat_img, fsaverage['pial_left'], inner_mesh=fsaverage['white_left']))\n",
    "    stat_img_list.append(surface.vol_to_surf(stat_img, fsaverage['pial_left'], inner_mesh=fsaverage['white_left']))\n",
    "    stat_img_list.append(surface.vol_to_surf(stat_img, fsaverage['pial_right'], inner_mesh=fsaverage['white_right']))\n",
    "    stat_img_list.append(surface.vol_to_surf(stat_img, fsaverage['pial_right'], inner_mesh=fsaverage['white_right']))\n",
    "    \n",
    "    figures, axes = plt.subplots(figsize=(25,25),nrows=1,ncols=4,subplot_kw={'projection': '3d'},sharex=True,sharey=True)\n",
    "    \n",
    "    #plot maps\n",
    "    plotting.plot_surf_stat_map(fsaverage.pial_left, colorbar=False, stat_map=stat_img_list[0], bg_map=fsaverage.sulc_left, hemi='left', view='lateral',\n",
    "                            darkness=0.95, alpha=0.71, axes=axes[0], threshold=vox_thresh, vmin=vmin_list[m_idx], vmax=vmax_list[m_idx])\n",
    "    plotting.plot_surf_stat_map(fsaverage.pial_left, colorbar=False, stat_map=stat_img_list[1], bg_map=fsaverage.sulc_left, hemi='left', view='medial',\n",
    "                            darkness=0.95, alpha=0.71, axes=axes[1], threshold=vox_thresh, vmin=vmin_list[m_idx], vmax=vmax_list[m_idx])\n",
    "    plotting.plot_surf_stat_map(fsaverage.pial_right, colorbar=False, stat_map=stat_img_list[2], bg_map=fsaverage.sulc_right, hemi='right', view='medial',\n",
    "                            darkness=0.95, alpha=0.71, axes=axes[2], threshold=vox_thresh, vmin=vmin_list[m_idx], vmax=vmax_list[m_idx])\n",
    "    plotting.plot_surf_stat_map(fsaverage.pial_right, colorbar=False, stat_map=stat_img_list[3], bg_map=fsaverage.sulc_right, hemi='right', view='lateral',\n",
    "                            darkness=0.95, alpha=0.71, axes=axes[3], threshold=vox_thresh, vmin=vmin_list[m_idx], vmax=vmax_list[m_idx])\n",
    "    \n",
    "    figures.subplots_adjust(wspace=0.01,hspace=0.00)\n",
    "    figures.savefig(os.path.join(PM_path,\"nilearn_plots\", (c_model[:-34]+'.png')), bbox_inches='tight')\n",
    "    plt.show() # plt.close('all')\n",
    "    \n",
    "    # ------------------ plot sagital surface plots w/ 17 networks ------------------ #\n",
    "    #figures, axes = plt.subplots(figsize=(15,20),nrows=1,ncols=4,subplot_kw={'projection': '3d'},sharex=True,sharey=True)\n",
    "    \n",
    "    # # plot atlas \n",
    "    # plotting.plot_surf_roi(fsaverage.pial_left, roi_map=n_textures[0], hemi='left', view='lateral',\n",
    "    #                     darkness=0.3, cmap=discrete_cmap, bg_on_data=True, bg_map=fsaverage.sulc_left, axes=axes[0])\n",
    "    # plotting.plot_surf_roi(fsaverage.pial_left, roi_map=n_textures[1], hemi='left', view='medial',\n",
    "    #                     darkness=0.3, cmap=discrete_cmap, bg_on_data=True, bg_map=fsaverage.sulc_left, axes=axes[1])\n",
    "    # plotting.plot_surf_roi(fsaverage.pial_right, roi_map=n_textures[2], hemi='right', view='medial',\n",
    "    #                     darkness=0.3, cmap=discrete_cmap, bg_on_data=True, bg_map=fsaverage.sulc_right, axes=axes[2])\n",
    "    # plotting.plot_surf_roi(fsaverage.pial_right, roi_map=n_textures[3], hemi='right', view='lateral',\n",
    "    #                     darkness=0.3, cmap=discrete_cmap, bg_on_data=True, bg_map=fsaverage.sulc_right, axes=axes[3])\n",
    "    \n",
    "    # #plot maps\n",
    "    # plotting.plot_surf_stat_map(fsaverage.pial_left, colorbar=False, stat_map=stat_img_list[0], bg_map=fsaverage.sulc_left, hemi='left', view='lateral',\n",
    "    #                         darkness=0.1, alpha=0.005, axes=axes[0], threshold=2.985, vmin=vmin_list[m_idx], vmax=vmax_list[m_idx])\n",
    "    # plotting.plot_surf_stat_map(fsaverage.pial_left, colorbar=False, stat_map=stat_img_list[1], bg_map=fsaverage.sulc_left, hemi='left', view='medial',\n",
    "    #                         darkness=0.1, alpha=0.005, axes=axes[1], threshold=2.985, vmin=vmin_list[m_idx], vmax=vmax_list[m_idx])\n",
    "    # plotting.plot_surf_stat_map(fsaverage.pial_right, colorbar=False, stat_map=stat_img_list[2], bg_map=fsaverage.sulc_right, hemi='right', view='medial',\n",
    "    #                         darkness=0.1, alpha=0.005, axes=axes[2], threshold=2.985, vmin=vmin_list[m_idx], vmax=vmax_list[m_idx])\n",
    "    # plotting.plot_surf_stat_map(fsaverage.pial_right, colorbar=False, stat_map=stat_img_list[3], bg_map=fsaverage.sulc_right, hemi='right', view='lateral',\n",
    "    #                         darkness=0.1, alpha=0.005, axes=axes[3], threshold=2.985, vmin=vmin_list[m_idx], vmax=vmax_list[m_idx])\n",
    "    \n",
    "    # #plot maps\n",
    "    # plotting.plot_surf_stat_map(fsaverage.pial_left, colorbar=False, stat_map=stat_img_list[0], bg_map=fsaverage.sulc_left, hemi='left', view='lateral',\n",
    "    #                         darkness=0.35, axes=axes[0], threshold=vox_thresh, vmin=vmin_list[m_idx], vmax=vmax_list[m_idx])\n",
    "    # plotting.plot_surf_stat_map(fsaverage.pial_left, colorbar=False, stat_map=stat_img_list[1], bg_map=fsaverage.sulc_left, hemi='left', view='medial',\n",
    "    #                         darkness=0.35, axes=axes[1], threshold=vox_thresh, vmin=vmin_list[m_idx], vmax=vmax_list[m_idx])\n",
    "    # plotting.plot_surf_stat_map(fsaverage.pial_right, colorbar=False, stat_map=stat_img_list[2], bg_map=fsaverage.sulc_right, hemi='right', view='medial',\n",
    "    #                         darkness=0.35, axes=axes[2], threshold=vox_thresh, vmin=vmin_list[m_idx], vmax=vmax_list[m_idx])\n",
    "    # plotting.plot_surf_stat_map(fsaverage.pial_right, colorbar=False, stat_map=stat_img_list[3], bg_map=fsaverage.sulc_right, hemi='right', view='lateral',\n",
    "    #                         darkness=0.35, axes=axes[3], threshold=vox_thresh, vmin=vmin_list[m_idx], vmax=vmax_list[m_idx])\n",
    "    \n",
    "    # plot_surf_contours(roi_map=n_textures[0], surf_mesh=fsaverage.pial_left, cmap=discrete_cmap, hemi='left', view='lateral', axes=axes[0])\n",
    "    # plot_surf_contours(roi_map=n_textures[1], surf_mesh=fsaverage.pial_left, cmap=discrete_cmap, hemi='left', view='lateral', axes=axes[1])\n",
    "    # plot_surf_contours(roi_map=n_textures[2], surf_mesh=fsaverage.pial_left, cmap=discrete_cmap, hemi='left', view='lateral', axes=axes[2])\n",
    "    # plot_surf_contours(roi_map=n_textures[3], surf_mesh=fsaverage.pial_left, cmap=discrete_cmap, hemi='left', view='lateral', axes=axes[3])\n",
    "    \n",
    "    figures.subplots_adjust(wspace=0.01,hspace=0.00)\n",
    "    figures.savefig(os.path.join(PM_path,\"nilearn_plots\", (c_model[:-34]+'_plus17networks.png')), bbox_inches='tight')\n",
    "    plt.show() # plt.close('all')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae12e904",
   "metadata": {},
   "source": [
    "Section 3\n",
    "\n",
    "# -----------------------------------------------------------------------------------------------------\n",
    "\n",
    "# - - - - - - - - - - - - - - - - - - -\n",
    "# - - -   Probabalistic Decoding  - - -\n",
    "# - - - - - - - - - - - - - - - - - - -"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddcde190",
   "metadata": {},
   "outputs": [],
   "source": [
    "PM_path = os.path.join(dataset_dir, \"Decoding\", \"GroupStats\")\n",
    "# ---- set up plot variables\n",
    "model_list = [\"jointP\", \"color\", \"state\", \"task\"]\n",
    "vmin_list = [-6, -6, -6, -6]\n",
    "vmax_list = [6, 6, 6, 6]\n",
    "\n",
    "custom_color_list_stats = custom_color_list.copy()\n",
    "custom_color_list_stats.append('gold')\n",
    "# -- set up custom color map for networks\n",
    "discrete_cmap_stats = mcolors.ListedColormap(custom_color_list_stats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62ef801d",
   "metadata": {},
   "outputs": [],
   "source": [
    "vox_thresh = 2.026 \n",
    "for epoch in [\"cue\",\"probe\"]:\n",
    "    for m_idx, c_model in enumerate(model_list):\n",
    "        # -- load current stat image sig clusters mask\n",
    "        brik_mask = nib.load(os.path.join(PM_path, (epoch+\"_\"+c_model+\"_masked.BRIK\"))) # load sig rois for state or color\n",
    "        brik_data = brik_mask.get_fdata()\n",
    "        if c_model==\"jointP\":\n",
    "            roi_data = np.where(np.squeeze(brik_data)>0,1,0) # binarize just in case its not already\n",
    "        elif c_model==\"task\":\n",
    "            roi_data = np.where(np.squeeze(brik_data)>0,1,0) # binarize just in case its not already \n",
    "        else:\n",
    "            roi_data = np.where(np.squeeze(brik_data)>1,1,0)\n",
    "        roi_data = np.where(np.squeeze(cortical_mask_data)>0,roi_data,0) # apply cortical mask too\n",
    "        mask_img = nib.Nifti1Image(roi_data, brik_mask.affine, brik_mask.header)\n",
    "        \n",
    "        stat_img0 = nib.load(os.path.join(PM_path, (\"GroupAnalysis_38subjs__\"+c_model+\"_\"+epoch+\"__r__tval.nii\")))\n",
    "        stat_masked = nilearn.masking.apply_mask(stat_img0, mask_img)\n",
    "        stat_img = masking.unmask(stat_masked, mask_img)\n",
    "        print(\"cur stat: \", c_model)\n",
    "        \n",
    "        # if c_model == \"state\":\n",
    "        #     cut_cords_list = [[-30, -16], [-12, -8, -2], [12, 20], [50, 56]] #left-medial, right-medial, left-lateral, right-lateral\n",
    "        # elif c_model == \"color\":\n",
    "        #     if epoch==\"cue\":\n",
    "        #         cut_cords_list = [[-8], [-8], [30, 33, 37], [45, 54, 64]]\n",
    "        #     else:\n",
    "        #         cut_cords_list = [[-6], [-6], [39], [52, 59]]\n",
    "        # elif c_model==\"task\":\n",
    "        #     cut_cords_list = [[-16, -9], [-1], [7, 16, 21, 30], [35, 47, 54, 64]]\n",
    "        # elif c_model==\"jointP\":\n",
    "        #     cut_cords_list = [[-16, -12, -9], [-1], [7, 16, 21, 30], [35, 47, 54, 64]]\n",
    "        cut_cords_list = [[-16, -11, -9, -2], [1, 6, 17], [20, 23, 32], [42, 52, 64]]\n",
    "\n",
    "        # ------------------ plot axial slices ------------------ #\n",
    "        L_sag_cuts = plotting.plot_stat_map(stat_map_img=stat_img, threshold=vox_thresh, cmap=plt.cm.RdBu_r, display_mode='z', cut_coords=cut_cords_list[0], vmin=vmin_list[m_idx], vmax=vmax_list[m_idx])\n",
    "        L_sag_cuts.savefig(os.path.join(PM_path,\"nilearn_plots\", (c_model+\"_\"+epoch+'__Inferior_Ax-1.png')))\n",
    "        plt.show() # plt.close('all')\n",
    "        R_sag_cuts = plotting.plot_stat_map(stat_map_img=stat_img, threshold=vox_thresh, cmap=plt.cm.RdBu_r, display_mode='z', cut_coords=cut_cords_list[1], vmin=vmin_list[m_idx], vmax=vmax_list[m_idx])\n",
    "        R_sag_cuts.savefig(os.path.join(PM_path,\"nilearn_plots\", (c_model+\"_\"+epoch+'__Inferior_Ax-2.png')))\n",
    "        plt.show() # plt.close('all')\n",
    "        \n",
    "        L_sag_cuts = plotting.plot_stat_map(stat_map_img=stat_img, threshold=vox_thresh, cmap=plt.cm.RdBu_r, display_mode='z', cut_coords=cut_cords_list[2], vmin=vmin_list[m_idx], vmax=vmax_list[m_idx])\n",
    "        L_sag_cuts.savefig(os.path.join(PM_path,\"nilearn_plots\", (c_model+\"_\"+epoch+'__Superior_Ax-1.png')))\n",
    "        plt.show() # plt.close('all')\n",
    "        R_sag_cuts = plotting.plot_stat_map(stat_map_img=stat_img, threshold=vox_thresh, cmap=plt.cm.RdBu_r, display_mode='z', cut_coords=cut_cords_list[3], vmin=vmin_list[m_idx], vmax=vmax_list[m_idx])\n",
    "        R_sag_cuts.savefig(os.path.join(PM_path,\"nilearn_plots\", (c_model+\"_\"+epoch+'__Superior_Ax-2.png')))\n",
    "        plt.show() # plt.close('all')\n",
    "        \n",
    "        \n",
    "        # ------------------ plot sagital surface plots ------------------ #\n",
    "        stat_img_list = []\n",
    "        stat_img_list.append(surface.vol_to_surf(stat_img, fsaverage['pial_left'], inner_mesh=fsaverage['white_left']))\n",
    "        stat_img_list.append(surface.vol_to_surf(stat_img, fsaverage['pial_left'], inner_mesh=fsaverage['white_left']))\n",
    "        stat_img_list.append(surface.vol_to_surf(stat_img, fsaverage['pial_right'], inner_mesh=fsaverage['white_right']))\n",
    "        stat_img_list.append(surface.vol_to_surf(stat_img, fsaverage['pial_right'], inner_mesh=fsaverage['white_right']))\n",
    "        \n",
    "        # n_textures_D = np.copy(n_textures)\n",
    "        # n_textures_D[0][stat_img_list[0]>0] = 18\n",
    "        # n_textures_D[1][stat_img_list[1]>0] = 18\n",
    "        # n_textures_D[2][stat_img_list[2]>0] = 18\n",
    "        # n_textures_D[3][stat_img_list[3]>0] = 18\n",
    "        \n",
    "        \n",
    "        figures, axes = plt.subplots(figsize=(15,15),nrows=1,ncols=4,subplot_kw={'projection': '3d'},sharex=True,sharey=True)\n",
    "            \n",
    "        #plot maps\n",
    "        plotting.plot_surf_stat_map(fsaverage.pial_left, colorbar=False, stat_map=stat_img_list[0], bg_map=fsaverage.sulc_left, hemi='left', view='lateral',\n",
    "                                darkness=0.95, alpha=0.71, axes=axes[0], threshold=vox_thresh, vmin=vmin_list[m_idx], vmax=vmax_list[m_idx])\n",
    "        plotting.plot_surf_stat_map(fsaverage.pial_left, colorbar=False, stat_map=stat_img_list[1], bg_map=fsaverage.sulc_left, hemi='left', view='medial',\n",
    "                                darkness=0.95, alpha=0.71, axes=axes[1], threshold=vox_thresh, vmin=vmin_list[m_idx], vmax=vmax_list[m_idx])\n",
    "        plotting.plot_surf_stat_map(fsaverage.pial_right, colorbar=False, stat_map=stat_img_list[2], bg_map=fsaverage.sulc_right, hemi='right', view='medial',\n",
    "                                darkness=0.95, alpha=0.71, axes=axes[2], threshold=vox_thresh, vmin=vmin_list[m_idx], vmax=vmax_list[m_idx])\n",
    "        plotting.plot_surf_stat_map(fsaverage.pial_right, colorbar=False, stat_map=stat_img_list[3], bg_map=fsaverage.sulc_right, hemi='right', view='lateral',\n",
    "                                darkness=0.95, alpha=0.71, axes=axes[3], threshold=vox_thresh, vmin=vmin_list[m_idx], vmax=vmax_list[m_idx])\n",
    "        \n",
    "        figures.subplots_adjust(wspace=0.01,hspace=0.00)\n",
    "        figures.savefig(os.path.join(PM_path, \"nilearn_plots\", (c_model+\"_\"+epoch+'.png')), bbox_inches='tight')\n",
    "        plt.show()\n",
    "        #plt.close('all')\n",
    "        \n",
    "        # # # ------------------ plot sagital surface plots w/ 17 networks ------------------ #\n",
    "        # # figures, axes = plt.subplots(figsize=(15,15),nrows=1,ncols=4,subplot_kw={'projection': '3d'},sharex=True,sharey=True)\n",
    "        \n",
    "        # # # # plot atlas \n",
    "        # # # plotting.plot_surf_roi(fsaverage.pial_left, roi_map=n_textures[0], hemi='left', view='lateral', colorbar=False, \n",
    "        # # #                     darkness=0.3, cmap=discrete_cmap_stats, bg_on_data=True, bg_map=fsaverage.sulc_left, axes=axes[0])\n",
    "        # # # plotting.plot_surf_roi(fsaverage.pial_left, roi_map=n_textures[1], hemi='left', view='medial', colorbar=False, \n",
    "        # # #                     darkness=0.3, cmap=discrete_cmap_stats, bg_on_data=True, bg_map=fsaverage.sulc_left, axes=axes[1])\n",
    "        # # # plotting.plot_surf_roi(fsaverage.pial_right, roi_map=n_textures[2], hemi='right', view='medial', colorbar=False, \n",
    "        # # #                     darkness=0.3, cmap=discrete_cmap_stats, bg_on_data=True, bg_map=fsaverage.sulc_right, axes=axes[2])\n",
    "        # # # plotting.plot_surf_roi(fsaverage.pial_right, roi_map=n_textures[3], hemi='right', view='lateral', colorbar=False, \n",
    "        # # #                     darkness=0.3, cmap=discrete_cmap_stats, bg_on_data=True, bg_map=fsaverage.sulc_right, axes=axes[3])\n",
    "        \n",
    "        # # #plot maps\n",
    "        # # plotting.plot_surf_stat_map(fsaverage.pial_left, colorbar=False, stat_map=stat_img_list[0], bg_map=fsaverage.sulc_left, hemi='left', view='lateral',\n",
    "        # #                         darkness=0.35, axes=axes[0], threshold=vox_thresh, vmin=vmin_list[m_idx], vmax=vmax_list[m_idx])\n",
    "        # # plotting.plot_surf_stat_map(fsaverage.pial_left, colorbar=False, stat_map=stat_img_list[1], bg_map=fsaverage.sulc_left, hemi='left', view='medial',\n",
    "        # #                         darkness=0.35, axes=axes[1], threshold=vox_thresh, vmin=vmin_list[m_idx], vmax=vmax_list[m_idx])\n",
    "        # # plotting.plot_surf_stat_map(fsaverage.pial_right, colorbar=False, stat_map=stat_img_list[2], bg_map=fsaverage.sulc_right, hemi='right', view='medial',\n",
    "        # #                         darkness=0.35, axes=axes[2], threshold=vox_thresh, vmin=vmin_list[m_idx], vmax=vmax_list[m_idx])\n",
    "        # # plotting.plot_surf_stat_map(fsaverage.pial_right, colorbar=False, stat_map=stat_img_list[3], bg_map=fsaverage.sulc_right, hemi='right', view='lateral',\n",
    "        # #                         darkness=0.35, axes=axes[3], threshold=vox_thresh, vmin=vmin_list[m_idx], vmax=vmax_list[m_idx])\n",
    "        \n",
    "        # # plot_surf_contours(roi_map=n_textures[0], surf_mesh=fsaverage.pial_left, cmap=discrete_cmap, hemi='left', view='lateral', axes=axes[0])\n",
    "        # # plot_surf_contours(roi_map=n_textures[1], surf_mesh=fsaverage.pial_left, cmap=discrete_cmap, hemi='left', view='lateral', axes=axes[1])\n",
    "        # # plot_surf_contours(roi_map=n_textures[2], surf_mesh=fsaverage.pial_left, cmap=discrete_cmap, hemi='left', view='lateral', axes=axes[2])\n",
    "        # # plot_surf_contours(roi_map=n_textures[3], surf_mesh=fsaverage.pial_left, cmap=discrete_cmap, hemi='left', view='lateral', axes=axes[3])\n",
    "        \n",
    "        # # # figures.subplots_adjust(wspace=0.01,hspace=0.00)\n",
    "        # # # figures.savefig(os.path.join(PM_path, \"nilearn_plots\", (c_model+\"_\"+epoch+'_plus17networks.png')), bbox_inches='tight')\n",
    "        # # plt.show()\n",
    "        # # #plt.close('all')\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "010c0d62",
   "metadata": {},
   "outputs": [],
   "source": [
    "# - - - - - - - - -\n",
    "# bar plots of number of clusters in each network\n",
    "# - - - - - - - - -\n",
    "# loop through each sig roi mask\n",
    "for epoch in [\"cue\",\"probe\"]:\n",
    "    for m_idx, c_mask in enumerate(model_list):\n",
    "        if c_mask==\"jointP\":\n",
    "            sns.set(rc={'figure.figsize':(5.5, 3.75)}) # width=10 inches, height=6 inches\n",
    "        elif c_mask==\"task\":\n",
    "            sns.set(rc={'figure.figsize':(5.5, 3.75)}) # width=10 inches, height=6 inches\n",
    "        else:\n",
    "            sns.set(rc={'figure.figsize':(5.5, 2.5)}) # width=10 inches, height=6 inches\n",
    "        print(\"working with \", c_mask)\n",
    "        # -- set up dict to save rois per network for bar plots\n",
    "        results_dict = {'ContA':0, 'ContB':0, 'ContC':0,\n",
    "                    'DefaultA':0, 'DefaultB':0, 'DefaultC':0,\n",
    "                    'DorsAttnA':0, 'DorsAttnB':0,\n",
    "                    'LimbicA':0, 'LimbicB':0,\n",
    "                    'SalVentAttnA':0, 'SalVentAttnB':0,\n",
    "                    'SomMotA':0, 'SomMotB':0,\n",
    "                    'TempPar':0,\n",
    "                    'VisCent':0, 'VisPeri':0}\n",
    "        total_voxel_count = 0\n",
    "        \n",
    "        # -- load current stat image sig clusters mask\n",
    "        stat_img0 = nib.load(os.path.join(PM_path, (\"GroupAnalysis_38subjs__\"+c_mask+\"_\"+epoch+\"__r__tval.nii\")))\n",
    "        brik_mask = nib.load(os.path.join(PM_path, (epoch+\"_\"+c_mask+\"_masked.BRIK\"))) # load sig rois for state or color\n",
    "        brik_data = brik_mask.get_fdata()\n",
    "        for roi in range(int(brik_data.max())):\n",
    "            # if roi==0:\n",
    "            #     if c_mask!=\"jointP\":\n",
    "            #         continue\n",
    "            #     elif c_mask!=\"task\":\n",
    "            #         continue # skip first roi for color, state, and task\n",
    "            sig_clust_data = np.where(np.squeeze(brik_data)==(roi+1),1,0) # binarize current roi\n",
    "            sig_clust_data = np.where(np.squeeze(cortical_mask_data)>0,sig_clust_data,0) # apply cortical mask too\n",
    "            sig_clust_img = nib.Nifti1Image(sig_clust_data, brik_mask.affine, brik_mask.header)\n",
    "            \n",
    "            try:\n",
    "                # mask stats data to see if cluster is pos or neg\n",
    "                stat_masked = nilearn.masking.apply_mask(stat_img0, sig_clust_img)\n",
    "                if stat_masked.mean() < 0:\n",
    "                    continue # skip this roi if it is negative\n",
    "                atlas_masked = nilearn.masking.apply_mask(resampled_atlas_img, sig_clust_img)\n",
    "                atlas_masked = atlas_masked[atlas_masked>0] # only use voxels with atlas labels so it all sums to 1\n",
    "            except:\n",
    "                print(\"error probably due to no data after masking.. just move on and skip this roi\")\n",
    "                continue\n",
    "            \n",
    "            #num_voxels_w_roi_labels = atlas_masked.shape \n",
    "            # -- okay pull networks that match rois with data\n",
    "            c_networks_list = [networks[(i-1)] for i in atlas_masked.astype(int)]\n",
    "            for c_net in c_networks_list:\n",
    "                results_dict[c_net] += 1 # add 1 to show 1 voxel overlapped with this sig cluster\n",
    "                total_voxel_count += 1\n",
    "            \n",
    "        for net_key in results_dict.keys():\n",
    "            results_dict[net_key] = results_dict[net_key] / total_voxel_count\n",
    "        \n",
    "        results_df = pd.DataFrame(results_dict, index=[0])\n",
    "        melt_df = pd.melt(results_df)\n",
    "        #print(melt_df)\n",
    "        sns.barplot(x='variable', y='value', data=melt_df, palette=custom_color_list, edgecolor='black', linewidth=1.5)\n",
    "        plt.title((epoch + \" \" + c_mask) + \"\\n\")\n",
    "        plt.xlabel(\"Network\")\n",
    "        plt.xticks(rotation=45, ha='right')\n",
    "        plt.ylabel(\"Proportion of sig. voxels\\noverlapping with network\")\n",
    "        if c_mask==\"jointP\":\n",
    "            plt.ylim((0,0.45))\n",
    "        elif c_mask==\"task\":\n",
    "            plt.ylim((0,0.45))\n",
    "        else:\n",
    "            plt.ylim((0,0.25))\n",
    "        \n",
    "        plt.savefig(os.path.join(PM_path, \"nilearn_plots\", (\"17networks__bar_plot__\"+c_mask+\"_\"+epoch+\".png\")), bbox_inches='tight')\n",
    "        \n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e28fcdb",
   "metadata": {},
   "source": [
    "Section 4\n",
    "\n",
    "# -----------------------------------------------------------------------------------------------------\n",
    "\n",
    "# - - - - - - - - - - - - - - - - - - -\n",
    "# - - -   Network Hubs  - - -\n",
    "# - - - - - - - - - - - - - - - - - - -"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de3724a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "PM_path = os.path.join(dataset_dir, \"Hubs\")\n",
    "# ---- set up plot variables\n",
    "c_model = \"Voxelwise_4mm_MGH_PC\"\n",
    "m_idx=0\n",
    "vmin_list = [0]\n",
    "vmax_list = [1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45094039",
   "metadata": {},
   "outputs": [],
   "source": [
    "vox_thresh = 0.65\n",
    "\n",
    "# -- load current stat image\n",
    "#mask_img = cortical_mask\n",
    "stat_img = nib.load(os.path.join(PM_path, (c_model+\".nii\")))\n",
    "#stat_masked = nilearn.masking.apply_mask(stat_img0, mask_img)\n",
    "#stat_img = masking.unmask(stat_masked, mask_img)\n",
    "print(\"cur stat: \", c_model)\n",
    "\n",
    "cut_cords_list = [[-16, -11, -9, -2], [1, 6, 17], [20, 23, 32], [42, 52, 64]]\n",
    "\n",
    "# ------------------ plot axial slices ------------------ #\n",
    "L_sag_cuts = plotting.plot_stat_map(stat_map_img=stat_img, threshold=vox_thresh, cmap=plt.cm.RdBu_r, display_mode='z', cut_coords=cut_cords_list[0], vmin=vmin_list[m_idx], vmax=vmax_list[m_idx])\n",
    "L_sag_cuts.savefig(os.path.join(PM_path,(c_model+'__Inferior_Ax-1.png')))\n",
    "plt.show() # plt.close('all')\n",
    "R_sag_cuts = plotting.plot_stat_map(stat_map_img=stat_img, threshold=vox_thresh, cmap=plt.cm.RdBu_r, display_mode='z', cut_coords=cut_cords_list[1], vmin=vmin_list[m_idx], vmax=vmax_list[m_idx])\n",
    "R_sag_cuts.savefig(os.path.join(PM_path,(c_model+'__Inferior_Ax-2.png')))\n",
    "plt.show() # plt.close('all')\n",
    "\n",
    "L_sag_cuts = plotting.plot_stat_map(stat_map_img=stat_img, threshold=vox_thresh, cmap=plt.cm.RdBu_r, display_mode='z', cut_coords=cut_cords_list[2], vmin=vmin_list[m_idx], vmax=vmax_list[m_idx])\n",
    "L_sag_cuts.savefig(os.path.join(PM_path,(c_model+'__Superior_Ax-1.png')))\n",
    "plt.show() # plt.close('all')\n",
    "R_sag_cuts = plotting.plot_stat_map(stat_map_img=stat_img, threshold=vox_thresh, cmap=plt.cm.RdBu_r, display_mode='z', cut_coords=cut_cords_list[3], vmin=vmin_list[m_idx], vmax=vmax_list[m_idx])\n",
    "R_sag_cuts.savefig(os.path.join(PM_path, (c_model+'__Superior_Ax-2.png')))\n",
    "plt.show() # plt.close('all')\n",
    "\n",
    "\n",
    "# # ------------------ plot sagital surface plots ------------------ #\n",
    "# stat_img_list = []\n",
    "# stat_img_list.append(surface.vol_to_surf(stat_img, fsaverage['pial_left'], inner_mesh=fsaverage['white_left']))\n",
    "# stat_img_list.append(surface.vol_to_surf(stat_img, fsaverage['pial_left'], inner_mesh=fsaverage['white_left']))\n",
    "# stat_img_list.append(surface.vol_to_surf(stat_img, fsaverage['pial_right'], inner_mesh=fsaverage['white_right']))\n",
    "# stat_img_list.append(surface.vol_to_surf(stat_img, fsaverage['pial_right'], inner_mesh=fsaverage['white_right']))\n",
    "\n",
    "# figures, axes = plt.subplots(figsize=(15,15),nrows=1,ncols=4,subplot_kw={'projection': '3d'},sharex=True,sharey=True)\n",
    "    \n",
    "# #plot maps\n",
    "# plotting.plot_surf_stat_map(fsaverage.pial_left, colorbar=False, stat_map=stat_img_list[0], bg_map=fsaverage.sulc_left, hemi='left', view='lateral',\n",
    "#                         darkness=0.95, alpha=0.71, axes=axes[0], threshold=vox_thresh, vmin=vmin_list[m_idx], vmax=vmax_list[m_idx])\n",
    "# plotting.plot_surf_stat_map(fsaverage.pial_left, colorbar=False, stat_map=stat_img_list[1], bg_map=fsaverage.sulc_left, hemi='left', view='medial',\n",
    "#                         darkness=0.95, alpha=0.71, axes=axes[1], threshold=vox_thresh, vmin=vmin_list[m_idx], vmax=vmax_list[m_idx])\n",
    "# plotting.plot_surf_stat_map(fsaverage.pial_right, colorbar=False, stat_map=stat_img_list[2], bg_map=fsaverage.sulc_right, hemi='right', view='medial',\n",
    "#                         darkness=0.95, alpha=0.71, axes=axes[2], threshold=vox_thresh, vmin=vmin_list[m_idx], vmax=vmax_list[m_idx])\n",
    "# plotting.plot_surf_stat_map(fsaverage.pial_right, colorbar=False, stat_map=stat_img_list[3], bg_map=fsaverage.sulc_right, hemi='right', view='lateral',\n",
    "#                         darkness=0.95, alpha=0.71, axes=axes[3], threshold=vox_thresh, vmin=vmin_list[m_idx], vmax=vmax_list[m_idx])\n",
    "\n",
    "# figures.subplots_adjust(wspace=0.01,hspace=0.00)\n",
    "# figures.savefig(os.path.join(PM_path, (c_model+'.png')), bbox_inches='tight')\n",
    "# plt.show()\n",
    "# #plt.close('all')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14d609b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# - - - - - - - - -\n",
    "# bar plots of number of clusters in each network\n",
    "# - - - - - - - - -\n",
    "# loop through each sig roi mask\n",
    "sns.set(rc={'figure.figsize':(5.5, 3.75)}) # width=10 inches, height=6 inches\n",
    "\n",
    "print(\"working with \", c_model)\n",
    "# -- set up dict to save rois per network for bar plots\n",
    "results_dict = {'ContA':0, 'ContB':0, 'ContC':0,\n",
    "            'DefaultA':0, 'DefaultB':0, 'DefaultC':0,\n",
    "            'DorsAttnA':0, 'DorsAttnB':0,\n",
    "            'LimbicA':0, 'LimbicB':0,\n",
    "            'SalVentAttnA':0, 'SalVentAttnB':0,\n",
    "            'SomMotA':0, 'SomMotB':0,\n",
    "            'TempPar':0,\n",
    "            'VisCent':0, 'VisPeri':0}\n",
    "total_voxel_count = 0\n",
    "\n",
    "stat_img = nib.load(os.path.join(PM_path, (c_model+\".nii\")))\n",
    "stat_data = stat_img.get_fdata()\n",
    "sig_clust_data = np.where(np.squeeze(stat_data)>0.65,1,0) # apply cortical mask too\n",
    "sig_clust_img = nib.Nifti1Image(sig_clust_data, stat_img.affine, stat_img.header)\n",
    "\n",
    "# Use NiftiLabelsMasker with the Schaefer atlas to extract ROI betas.\n",
    "masker = NiftiLabelsMasker(labels_img=atlas_img, standardize=False)\n",
    "atlas_4mm_img = resample_img(atlas_img, target_affine=stat_img.affine, target_shape=stat_img.shape, interpolation='nearest', force_resample=True)\n",
    "\n",
    "try:\n",
    "    atlas_masked = nilearn.masking.apply_mask(atlas_4mm_img, sig_clust_img)\n",
    "    atlas_masked = atlas_masked[atlas_masked>0] # only use voxels with atlas labels so it all sums to 1\n",
    "except:\n",
    "    print(\"error probably due to no data after masking.. just move on and skip this roi\")\n",
    "    \n",
    "# -- okay pull networks that match rois with data\n",
    "c_networks_list = [networks[(i-1)] for i in atlas_masked.astype(int)]\n",
    "for c_net in c_networks_list:\n",
    "    results_dict[c_net] += 1 # add 1 to show 1 voxel overlapped with this sig cluster\n",
    "    total_voxel_count += 1\n",
    "    \n",
    "for net_key in results_dict.keys():\n",
    "    results_dict[net_key] = results_dict[net_key] / total_voxel_count\n",
    "\n",
    "results_df = pd.DataFrame(results_dict, index=[0])\n",
    "melt_df = pd.melt(results_df)\n",
    "#print(melt_df)\n",
    "sns.barplot(x='variable', y='value', data=melt_df, palette=custom_color_list, edgecolor='black', linewidth=1.5)\n",
    "plt.title((c_model) + \"\\n\")\n",
    "plt.xlabel(\"Network\")\n",
    "plt.xticks(rotation=45, ha='right')\n",
    "plt.ylabel(\"Proportion of sig. voxels\\noverlapping with network\")\n",
    "plt.ylim((0,0.45))\n",
    "\n",
    "plt.savefig(os.path.join(PM_path, (\"17networks__bar_plot__\"+c_model+\".png\")), bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e81ebb4c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "plotting_env",
   "language": "python",
   "name": "myenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
